{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n// 기본\\nclass FeedConvert(config):\\n    def load\\n        \\n    def convert\\n        df.apply(lambda x : customConvert(x), axis=1)    \\n        df.apply(lambda x : mediaConvert(x), axis=1)\\n        \\n    def write\\n        \\n    def upload\\n        \\n\\n// 고객사별 조건\\ndef customConvert(df)    \\n    -lambda로 실행\\n    -관리편의를 위해 로직을 catalog id기준으로 묶어놓음\\n    -add/remove\\n    -fit field\\n    -replace value\\n    -set link\\n    -default value\\n\\n// 매체별 조건 (생략?)\\ndef FacebookConvert()\\ndef GoogleConvert()\\ndef CriteoConvert()\\n\\n// test 용이하도록\\n\\n// log 확인 \\n\\n// linux process 관리가능? \\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "'''\n",
    "ssg_ep의 경우 10G 다운받는과정만 6시간정도 걸리는데, \n",
    "대부분 mysql insert과정에서 시간소요되는듯\n",
    "다운을 먼저 받고 batch insert를 날리던가 \n",
    "db에 저장하지 않는 방식으로 진행하면 속도문제 해결\n",
    "\n",
    "181서버에서 10G다운받는 시간 약2분\n",
    "pandas를 통해 처리후 파일생성(zip) 시간 약3분\n",
    "\n",
    "증분업데이트도 이런식으로 처리하면 서버부하 거의없지않을까?\n",
    "피드내용 확인하는 로직만 필요없다면 가능할것같음\n",
    "\n",
    "fastapi로 api서버 구동해서 스케줄마다 실행시키면 관리하기 수월할듯?\n",
    "\n",
    "// 기본\n",
    "class FeedConvert(config):\n",
    "    def load\n",
    "        \n",
    "    def convert\n",
    "        df.apply(lambda x : customConvert(x), axis=1)    \n",
    "        df.apply(lambda x : mediaConvert(x), axis=1)\n",
    "        \n",
    "    def write\n",
    "        \n",
    "    def upload\n",
    "        \n",
    "\n",
    "// 고객사별 조건\n",
    "def customConvert(df)    \n",
    "    -lambda로 실행\n",
    "    -관리편의를 위해 로직을 catalog id기준으로 묶어놓음\n",
    "    -add/remove\n",
    "    -fit field\n",
    "    -replace value\n",
    "    -set link\n",
    "    -default value\n",
    "\n",
    "// 매체별 조건 (생략?)\n",
    "def FacebookConvert()\n",
    "def GoogleConvert()\n",
    "def CriteoConvert()\n",
    "\n",
    "// test 용이하도록\n",
    "\n",
    "// log 확인 \n",
    "\n",
    "// linux process 관리가능? \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import os\n",
    "import gc\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "          'info': \n",
    "          {\n",
    "            'media': 'facebook',\n",
    "            'catalog_id' : '268046537186348',\n",
    "            'feed_id' : '',\n",
    "            'name': 'ssg_ep_test',\n",
    "          },\n",
    "          'read':\n",
    "          {\n",
    "            'path' : 'C:/Users/shsun/Documents/workspace/project/p1/f1_feed_change_min/data/dumy_10g.csv',\n",
    "            'format' : 'csv',\n",
    "            'encoding' : 'utf-16',\n",
    "            'chunkSize' : 100000\n",
    "          },\n",
    "          'write':{\n",
    "            'path': 'C:/Users/shsun/Documents/workspace/project/p1/f1_feed_change_min/data/saved_test.txt',\n",
    "            'zipPath': 'C:/Users/shsun/Documents/workspace/project/p1/f1_feed_change_min/data/zip_test.zip',\n",
    "            'encoding' : 'utf-8'\n",
    "          },\n",
    "          'field' : \n",
    "            {\n",
    "              'id' : 'id', \n",
    "              'title' : 'title',\n",
    "              'link' : 'link',\n",
    "              'image_link' : 'image_link',\n",
    "              'price' : 'value',\n",
    "              'brand' : 'brand',\n",
    "              'description' : 'description',\n",
    "              'availability' : 'availability'\n",
    "            },\n",
    "          'filter': # ep to feed\n",
    "          {            \n",
    "            'remove' : {'title': ['마스크','소독제','손소독겔','새니타이저','손살균제','sanitizers','disinfection wipes']}, #키워드 제외\n",
    "          }\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedConvert():\n",
    "    def __init__(self,config):\n",
    "        self.config = config\n",
    "    \n",
    "    def customConvert(self, dataframe):\n",
    "        # 공통\n",
    "        keys = list(self.config['field'].keys())\n",
    "        dataframe = dataframe[keys] # 필요컬럼만 추출\n",
    "        dataframe.rename(columns= self.config['field'], inplace=True) # key 수정\n",
    "\n",
    "        # 카탈로그별 필요에따라 로직 + config 로 관리        \n",
    "        # 개별 로직\n",
    "        if self.config['info']['media'] == 'facebook' and\n",
    "           self.config['info']['catalog_id'] == '268046537186348' :\n",
    "            # add\n",
    "            if 'add' in self.config['filter']:\n",
    "                key = list(self.config['filter']['add'].keys())[0]                \n",
    "                value = self.config['filter']['add'][key]                \n",
    "                dataframe = dataframe.loc[dataframe[key].isin(value)] #포함\n",
    "            # remove\n",
    "            if 'remove' in self.config['filter']:\n",
    "                key = list(self.config['filter']['remove'].keys())[0]\n",
    "                value = self.config['filter']['remove'][key]\n",
    "                dataframe = dataframe.loc[~dataframe[key].isin(value)] #제외\n",
    "            # replace value\n",
    "            \n",
    "            # set link\n",
    "            \n",
    "            return dataframe\n",
    "        \n",
    "        elif self.config['info']['catalog_id'] == '0000001':\n",
    "            pass\n",
    "            \n",
    "        \n",
    "    def mediaConvert():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeedConvertProcess():        \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.feedConvert = FeedConvert(self.config) #convert관리 class\n",
    "        \n",
    "        \n",
    "    def epLoad(self):\n",
    "        # 클래스로 따로 빼야하나?\n",
    "        \n",
    "        # pixel로 관리되는 tracking data\n",
    "        \n",
    "        # ep데이터 있는경우\n",
    "        if config['read']['format'] == 'xml':\n",
    "            # xml은 따로 로드함\n",
    "            result = etree.iterparse(self.config['read']['path'])\n",
    "            \n",
    "        else:\n",
    "            # chunksize 단위로 쪼개서 로드        \n",
    "            result = pd.read_csv(self.config['read']['path'], \n",
    "                                 chunksize=self.config['read']['chunkSize'], \n",
    "                                 delimiter=',', \n",
    "                                 encoding=self.config['read']['encoding'])\n",
    "\n",
    "        # iterator포함 객체로 출력\n",
    "        return result\n",
    "        \n",
    "        \n",
    "    # def ep2Feed(self, df):        \n",
    "    #     # custom convert    \n",
    "    #     # media convert    \n",
    "    #     return result\n",
    "\n",
    "    def feedWrite(self, num, df):\n",
    "        if num == 0:\n",
    "            df.to_csv(self.config['write']['path'], index=True, sep='\\t', mode='w', encoding=self.config['write']['encoding'])\n",
    "        else:\n",
    "            df.to_csv(self.config['write']['path'], index=True, sep='\\t', mode='a', encoding=self.config['write']['encoding'], header=False)\n",
    "        \n",
    "        print((num+1)*self.config['read']['chunkSize'], end='..', flush=True)    \n",
    "    \n",
    "    def feedUpload(self):\n",
    "        # zip\n",
    "        zf = zipfile.ZipFile(self.config['write']['zipPath'], mode='w')\n",
    "        zf.write(self.config['write']['path'], compress_type=zipfile.ZIP_DEFLATED)\n",
    "        zf.close()\n",
    "        # upload\n",
    "        \n",
    "        # delete\n",
    "\n",
    "\n",
    "    def execute(self):                \n",
    "        for num, chunkDF in enumerate(self.epLoad()): # chunk load            \n",
    "            # convert\n",
    "            chunkDF = self.feedConvert.customConvert(chunkDF)\n",
    "\n",
    "            # file write\n",
    "            self.feedWrite(num, chunkDF)\n",
    "            \n",
    "            # cleaning\n",
    "            del [[chunkDF]]\n",
    "            gc.collect()\n",
    "\n",
    "            # break\n",
    "            # if num >= 10:\n",
    "            #     break\n",
    "                \n",
    "        \n",
    "        self.feedUpload()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcp = FeedConvertProcess(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100000..200000..300000..400000..500000..600000..700000..800000..900000..1000000..1100000..1200000..1300000..1400000..1500000..1600000..1700000..1800000..1900000..2000000..2100000..2200000..2300000..2400000..2500000..2600000..2700000..2800000..2900000..3000000..3100000..3200000..3300000..3400000..3500000..3600000..3700000..3800000..3900000..4000000..4100000..4200000..4300000..4400000..4500000..4600000..4700000..4800000..4900000..5000000..5100000..5200000..5300000..5400000..5500000..5600000..5700000..5800000..5900000..6000000..6100000..6200000..6300000..6400000..6500000..6600000..6700000..6800000..6900000..7000000..7100000..7200000..7300000..7400000..7500000..7600000..7700000..7800000..7900000..8000000..8100000..8200000..8300000..8400000..8500000..8600000..8700000..8800000..8900000..9000000..9100000..9200000..9300000..9400000..9500000..9600000..Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fcp.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}